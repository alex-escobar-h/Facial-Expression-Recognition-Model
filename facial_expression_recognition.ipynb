{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-escobar-h/Facial-Expression-Recognition-Model/blob/main/facial_expression_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ac6de0",
      "metadata": {
        "id": "97ac6de0"
      },
      "source": [
        "# Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install FER-2013 Dataset from Kaggle"
      ],
      "metadata": {
        "id": "-sy9vkIT5u3O"
      },
      "id": "-sy9vkIT5u3O"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "9503c90b",
      "metadata": {
        "id": "9503c90b",
        "outputId": "aa0dee69-e20c-4fdc-9db1-f91c0c22cc09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d msambare/fer2013\n",
        "!unzip -q fer2013.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "a9UPESzcR2El"
      },
      "id": "a9UPESzcR2El"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader Class"
      ],
      "metadata": {
        "id": "s5UHWwKzFmc2"
      },
      "id": "s5UHWwKzFmc2"
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch.utils.data\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir=\".\",\n",
        "        batch_size=32,\n",
        "        valid_size=0.2,\n",
        "        image_size=48,\n",
        "        num_workers=0,\n",
        "    ):\n",
        "        self.batch_size = batch_size\n",
        "        self.valid_size = valid_size\n",
        "        self.image_size = image_size\n",
        "        self.data_dir = data_dir\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "        self.classes = [\n",
        "            \"angry\",\n",
        "            \"disgust\",\n",
        "            \"fear\",\n",
        "            \"happy\",\n",
        "            \"neutral\",\n",
        "            \"sad\",\n",
        "            \"surprise\",\n",
        "        ]\n",
        "        self.train_loader, self.valid_loader, self.test_loader = self._prepare_loaders()\n",
        "\n",
        "    def _train_transform(self):\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                # transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.Resize((self.image_size, self.image_size)),\n",
        "                transforms.Grayscale(num_output_channels=1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _test_transform(self):\n",
        "        return transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((self.image_size, self.image_size)),\n",
        "                transforms.Grayscale(num_output_channels=1),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def _prepare_loaders(self):\n",
        "        # Load datasets\n",
        "        train_data = datasets.ImageFolder(\n",
        "            root=f\"{self.data_dir}/train\", transform=self._train_transform()\n",
        "        )\n",
        "        test_data = datasets.ImageFolder(\n",
        "            root=f\"{self.data_dir}/test\", transform=self._test_transform()\n",
        "        )\n",
        "\n",
        "        # Split train into train/val\n",
        "        num_train = len(train_data)\n",
        "        indices = list(range(num_train))\n",
        "        np.random.shuffle(indices)\n",
        "        split = int(np.floor(self.valid_size * num_train))\n",
        "        if self.valid_size > 0 and split == 0:\n",
        "            split = 1  # Ensure at least one sample in validation set\n",
        "        train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "        train_sampler = SubsetRandomSampler(train_idx)\n",
        "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_data,\n",
        "            batch_size=self.batch_size,\n",
        "            sampler=train_sampler,\n",
        "            num_workers=self.num_workers,\n",
        "        )\n",
        "        valid_loader = torch.utils.data.DataLoader(\n",
        "            train_data,\n",
        "            batch_size=self.batch_size,\n",
        "            sampler=valid_sampler,\n",
        "            num_workers=self.num_workers,\n",
        "        )\n",
        "        test_loader = torch.utils.data.DataLoader(\n",
        "            test_data, batch_size=self.batch_size, num_workers=self.num_workers\n",
        "        )\n",
        "\n",
        "        return train_loader, valid_loader, test_loader"
      ],
      "metadata": {
        "id": "qbIzLaqHQfV0"
      },
      "id": "qbIzLaqHQfV0",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Class"
      ],
      "metadata": {
        "id": "qxaqEMdtRxyX"
      },
      "id": "qxaqEMdtRxyX"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_block1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 48x48 → 24x24\n",
        "        )\n",
        "\n",
        "        self.conv_block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3),  # 24x24 → 22x22\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3),  # 22x22 → 20x20\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 20x20 → 10x10\n",
        "        )\n",
        "\n",
        "        self.conv_block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3),  # 10x10 → 8x8\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # 8x8 → 4x4\n",
        "        )\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.output = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.output(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kUbNhy2kR6QO"
      },
      "id": "kUbNhy2kR6QO",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ModelTrainer Class"
      ],
      "metadata": {
        "id": "hV_1-GFkSSUu"
      },
      "id": "hV_1-GFkSSUu"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTrainer:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        train_loader,\n",
        "        valid_loader,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        device,\n",
        "        save_path=\"model_trained.pt\",\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.valid_loader = valid_loader\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.save_path = save_path\n",
        "        self.best_valid_loss = float(\"inf\")\n",
        "\n",
        "    def train(self, num_epochs=5):\n",
        "        for epoch in range(1, num_epochs + 1):\n",
        "            train_loss = self._train_epoch()\n",
        "            valid_loss = self._validate_epoch()\n",
        "            print(\n",
        "                f\"Epoch {epoch} \\tTrain Loss: {train_loss:.6f} \\tVal Loss: {valid_loss:.6f}\"\n",
        "            )\n",
        "\n",
        "            if valid_loss < self.best_valid_loss:\n",
        "                print(\n",
        "                    f\"Validation loss decreased ({self.best_valid_loss:.6f} --> {valid_loss:.6f}). Saving model...\"\n",
        "                )\n",
        "                torch.save(self.model.state_dict(), self.save_path)\n",
        "                self.best_valid_loss = valid_loss\n",
        "\n",
        "    def _train_epoch(self):\n",
        "        self.model.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for data, target in self.train_loader:\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "            self.optimizer.zero_grad()\n",
        "            output = self.model(data)\n",
        "            loss = self.criterion(output, target)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            total_loss += loss.item() * data.size(0)\n",
        "\n",
        "        return total_loss / len(self.train_loader.sampler)\n",
        "\n",
        "    def _validate_epoch(self):\n",
        "        self.model.eval()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in self.valid_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                total_loss += loss.item() * data.size(0)\n",
        "\n",
        "        return total_loss / len(self.valid_loader.sampler)\n"
      ],
      "metadata": {
        "id": "NFSO5Jk1SR-S"
      },
      "id": "NFSO5Jk1SR-S",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ModelTester Class"
      ],
      "metadata": {
        "id": "s0Ir2sFDSbgw"
      },
      "id": "s0Ir2sFDSbgw"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelTester:\n",
        "    def __init__(self, model, test_loader, criterion, classes, device):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            model (nn.Module): trained model\n",
        "            test_loader (DataLoader): data loader for test set\n",
        "            criterion (loss function): loss function used\n",
        "            classes (list): list of class labels\n",
        "            device (torch.device): device to run evaluation on\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.test_loader = test_loader\n",
        "        self.criterion = criterion\n",
        "        self.classes = classes\n",
        "        self.device = device\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        test_loss = 0.0\n",
        "        num_classes = len(self.classes)\n",
        "        class_correct = [0.0 for _ in range(num_classes)]\n",
        "        class_total = [0.0 for _ in range(num_classes)]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in self.test_loader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                test_loss += loss.item() * data.size(0)\n",
        "\n",
        "                _, pred = torch.max(output, 1)\n",
        "                correct_tensor = pred.eq(target.view_as(pred))\n",
        "                correct = correct_tensor.cpu().numpy()\n",
        "\n",
        "                for i in range(len(target)):\n",
        "                    label = target[i].item()\n",
        "                    class_correct[label] += correct[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "        test_loss /= len(self.test_loader.dataset)\n",
        "        print(f\"\\nTest Loss: {test_loss:.6f}\\n\")\n",
        "\n",
        "        for i in range(num_classes):\n",
        "            if class_total[i] > 0:\n",
        "                acc = 100.0 * class_correct[i] / class_total[i]\n",
        "                print(\n",
        "                    f\"Test Accuracy of {self.classes[i]:8s}: {acc:2.0f}% \"\n",
        "                    f\"({int(class_correct[i])}/{int(class_total[i])})\"\n",
        "                )\n",
        "            else:\n",
        "                print(f\"Test Accuracy of {self.classes[i]:8s}: N/A (no samples)\")\n",
        "\n",
        "        overall = 100.0 * np.sum(class_correct) / np.sum(class_total)\n",
        "        print(f\"\\nTest Accuracy (Overall): {overall:.2f}%\")\n"
      ],
      "metadata": {
        "id": "WjJc_59-Sd5-"
      },
      "id": "WjJc_59-Sd5-",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ImageVisualizer Class"
      ],
      "metadata": {
        "id": "mEyEERtuSj0h"
      },
      "id": "mEyEERtuSj0h"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ImageVisualizer:\n",
        "    def __init__(self, class_labels):\n",
        "        self.class_labels = class_labels\n",
        "\n",
        "    def imshow(self, img):\n",
        "        img = img / 2 + 0.5  # unnormalize\n",
        "        npimg = img.cpu().numpy()\n",
        "        if npimg.shape[0] == 1:\n",
        "            npimg = npimg.squeeze()\n",
        "            plt.imshow(npimg, cmap=\"gray\")\n",
        "        else:\n",
        "            npimg = np.transpose(npimg, (1, 2, 0))\n",
        "            plt.imshow(npimg)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    def show_batch(self, images, labels, n=32, rows=4, cols=8):\n",
        "        fig = plt.figure(figsize=(cols * 3, rows * 3))\n",
        "        for idx in np.arange(min(n, len(images))):\n",
        "            ax = fig.add_subplot(rows, cols, idx + 1, xticks=[], yticks=[])\n",
        "            self.imshow(images[idx])\n",
        "            ax.set_title(self.class_labels[labels[idx]])\n",
        "        plt.show()\n",
        "\n",
        "    def show_predictions(self, images, labels, preds, n=20, rows=2, cols=10):\n",
        "        fig = plt.figure(figsize=(cols * 3, rows * 3))\n",
        "        for idx in np.arange(min(n, len(images))):\n",
        "            ax = fig.add_subplot(rows, cols, idx + 1, xticks=[], yticks=[])\n",
        "            self.imshow(images[idx])\n",
        "            pred_label = self.class_labels[preds[idx]]\n",
        "            true_label = self.class_labels[labels[idx]]\n",
        "            color = \"green\" if preds[idx] == labels[idx].item() else \"red\"\n",
        "            ax.set_title(f\"{pred_label} ({true_label})\", color=color)\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "5n_hY4BZSjem"
      },
      "id": "5n_hY4BZSjem",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "AQUcrr7BRhSY"
      },
      "id": "AQUcrr7BRhSY"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on: {device}\")\n",
        "\n",
        "data_loader = DataLoader(batch_size=16)\n",
        "\n",
        "# 2. Instantiate model and move it to device\n",
        "model = CNN()      # Use CNN for a simple model\n",
        "# model = Net()     # Use CNN2 for a more complex model\n",
        "# model = VGGMini()   # Use VGGMini for a smaller model\n",
        "model.to(device)\n",
        "\n",
        "# 3. Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 4. Instantiate trainer and start training\n",
        "trainer = ModelTrainer(\n",
        "    model,\n",
        "    data_loader.train_loader,\n",
        "    data_loader.valid_loader,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    device,\n",
        ")\n",
        "trainer.train(15)\n",
        "tester = ModelTester(\n",
        "    model, data_loader.test_loader, criterion, data_loader.classes, device\n",
        ")\n",
        "tester.evaluate()\n",
        "\n",
        "# 5. Visualize predictions on a test batch\n",
        "visualizer = ImageVisualizer(class_labels=data_loader.classes)\n",
        "\n",
        "# Get one batch of test data\n",
        "dataiter = iter(data_loader.test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Move images to the appropriate device\n",
        "images_device = images.to(device)\n",
        "\n",
        "# Set model to eval mode and get predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(images_device)\n",
        "    _, preds_tensor = torch.max(outputs, 1)\n",
        "    preds = preds_tensor.cpu().numpy()  # Always move to CPU for visualization\n",
        "\n",
        "# Show predictions (move images to CPU if needed)\n",
        "visualizer.show_predictions(images.cpu(), labels, preds, n=20, rows=2, cols=10)\n"
      ],
      "metadata": {
        "id": "KerMMwMrQ7w3",
        "outputId": "1b8e2faf-2c01-456e-be49-0e969ebf5885",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on: cpu\n"
          ]
        }
      ],
      "id": "KerMMwMrQ7w3"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}