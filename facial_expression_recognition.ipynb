{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-escobar-h/Facial-Expression-Recognition-Model/blob/main/facial_expression_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97ac6de0",
      "metadata": {
        "id": "97ac6de0"
      },
      "source": [
        "# Facial Expression Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install FER-2013 Dataset from Kaggle"
      ],
      "metadata": {
        "id": "-sy9vkIT5u3O"
      },
      "id": "-sy9vkIT5u3O"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9503c90b",
      "metadata": {
        "id": "9503c90b",
        "outputId": "5cee49a6-d476-4641-d918-09f2cc3560d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY')\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME')\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d msambare/fer2013\n",
        "!unzip -q fer2013.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation and Transforms"
      ],
      "metadata": {
        "id": "_PUd5XM4i3w8"
      },
      "id": "_PUd5XM4i3w8"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.5],std=[0.5])\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "# Define transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(48,scale=(0.9, 1.1), ratio=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize((48,48)),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset_full = datasets.ImageFolder(root='/content/train', transform=train_transform)\n",
        "\n",
        "# Split training data into training and validation (80%/20%)\n",
        "val_dataset_size = int(0.2*len(train_dataset_full))\n",
        "train_dataset_size = len(train_dataset_full) - val_dataset_size\n",
        "\n",
        "# Randomly split the full training dataset into 80% training and 20% validation subsets.\n",
        "# The manual seed ensures reproducibility - the same split every time this code runs.\n",
        "train_dataset, val_dataset = random_split(\n",
        "    train_dataset_full,[train_dataset_size,val_dataset_size], generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "train_dataset.dataset.transform=train_transform\n",
        "val_dataset.dataset.transform=val_test_transform\n",
        "\n",
        "test_dataset = datasets.ImageFolder('/content/test', transform=val_test_transform)\n",
        "\n",
        "# Wrap datasets in DataLoaders\n",
        "train_loader = DataLoader(train_dataset,batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset,batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset,batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Retrieve classifications from training dataset\n",
        "classes = train_dataset.dataset.classes\n",
        "print(classes)"
      ],
      "metadata": {
        "id": "mgNBuInni6wJ",
        "outputId": "5f334fa1-ab29-4803-98f2-8879df8cf5cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "mgNBuInni6wJ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Class"
      ],
      "metadata": {
        "id": "qxaqEMdtRxyX"
      },
      "id": "qxaqEMdtRxyX"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=20, out_channels=40, kernel_size=3, padding=1\n",
        "        )\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=40, out_channels=80, kernel_size=3, padding=1\n",
        "        )\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "        # After 3 conv + 3 pool layers:\n",
        "        # 48 -> 24 -> 12 -> 6 -> final feature map size: [80, 6, 6]\n",
        "        self.fc1 = nn.Linear(in_features=80 * 6 * 6, out_features=600)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=7)  # 7 emotion classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # [20, 24, 24]\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # [40, 12, 12]\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # [80, 6, 6]\n",
        "\n",
        "        x = x.view(-1, 80 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kUbNhy2kR6QO"
      },
      "id": "kUbNhy2kR6QO",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and Validation Loop"
      ],
      "metadata": {
        "id": "1_YmjZkhjs5Z"
      },
      "id": "1_YmjZkhjs5Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "model = CNN()\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "n_epochs = 5\n",
        "valid_loss_min = np.inf  # track change in validation loss\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    ###################\n",
        "    # Train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * data.size(0)\n",
        "\n",
        "    ######################\n",
        "    # Validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(val_loader):\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "    train_loss = train_loss / len(train_loader.dataset)\n",
        "    valid_loss = valid_loss / len(val_loader.dataset)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min, valid_loss))\n",
        "        torch.save(model.state_dict(), 'model_trained.pt')\n",
        "        valid_loss_min = valid_loss"
      ],
      "metadata": {
        "id": "UYWq07Z8jvKs",
        "outputId": "fd452da0-a892-4bdb-d5af-e955e31f59bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UYWq07Z8jvKs",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "Epoch: 1 \tTraining Loss: 1.612053 \tValidation Loss: 1.413038\n",
            "Validation loss decreased (inf --> 1.413038).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 1.352848 \tValidation Loss: 1.315712\n",
            "Validation loss decreased (1.413038 --> 1.315712).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1.222326 \tValidation Loss: 1.231621\n",
            "Validation loss decreased (1.315712 --> 1.231621).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1.112960 \tValidation Loss: 1.213738\n",
            "Validation loss decreased (1.231621 --> 1.213738).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1.006312 \tValidation Loss: 1.225506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "-iur4Qzhk9EA"
      },
      "id": "-iur4Qzhk9EA"
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "test_loss = 0.0\n",
        "num_classes = len(classes)\n",
        "class_correct = [0. for _ in range(num_classes)]\n",
        "class_total = [0. for _ in range(num_classes)]\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        test_loss += loss.item() * data.size(0)\n",
        "\n",
        "        _, pred = torch.max(output, 1)\n",
        "        correct_tensor = pred.eq(target.view_as(pred))\n",
        "        correct = correct_tensor.cpu().numpy() if train_on_gpu else correct_tensor.numpy()\n",
        "\n",
        "        for i in range(len(target)):\n",
        "            label = target[i].item()\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "# Compute average loss\n",
        "test_loss = test_loss / len(test_loader.dataset)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "# Print per-class accuracy\n",
        "for i in range(num_classes):\n",
        "    if class_total[i] > 0:\n",
        "        acc = 100 * class_correct[i] / class_total[i]\n",
        "        print('Test Accuracy of %8s: %2d%% (%d/%d)' %\n",
        "              (classes[i], int(acc), int(class_correct[i]), int(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no test examples)' % classes[i])\n",
        "\n",
        "# Print overall accuracy\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ],
      "metadata": {
        "id": "qXO82d3Wk-PA",
        "outputId": "005869a8-35d3-4fd5-a25f-1270d3b15abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qXO82d3Wk-PA",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.111451\n",
            "\n",
            "Test Accuracy of    angry: 56% (537/958)\n",
            "Test Accuracy of  disgust: 40% (45/111)\n",
            "Test Accuracy of     fear: 20% (215/1024)\n",
            "Test Accuracy of    happy: 82% (1468/1774)\n",
            "Test Accuracy of  neutral: 57% (708/1233)\n",
            "Test Accuracy of      sad: 44% (559/1247)\n",
            "Test Accuracy of surprise: 76% (638/831)\n",
            "\n",
            "Test Accuracy (Overall): 58% (4170/7178)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}